{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use Text Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alvaro-francisco-gil/text-rank/blob/main/examples/using_text_rank.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install  Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/alvaro-francisco-gil/text-rank.git\n",
      "  Cloning https://github.com/alvaro-francisco-gil/text-rank.git to c:\\users\\alvar\\appdata\\local\\temp\\pip-req-build-zfufp3pd\n",
      "  Resolved https://github.com/alvaro-francisco-gil/text-rank.git to commit 362e4434bfc3f613f90c04ec50c01e4ccbcae6f1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk>=3.7 in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from text_rank==0.1) (3.9.1)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from text_rank==0.1) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from text_rank==0.1) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from text_rank==0.1) (1.15.2)\n",
      "Requirement already satisfied: click in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from nltk>=3.7->text_rank==0.1) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from nltk>=3.7->text_rank==0.1) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from nltk>=3.7->text_rank==0.1) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from nltk>=3.7->text_rank==0.1) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvar\\anaconda3\\envs\\text_rank_env\\lib\\site-packages (from click->nltk>=3.7->text_rank==0.1) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/alvaro-francisco-gil/text-rank.git 'C:\\Users\\alvar\\AppData\\Local\\Temp\\pip-req-build-zfufp3pd'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/alvaro-francisco-gil/text-rank.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_rank import TextRankKeywordExtractor\n",
    "\n",
    "extractor = TextRankKeywordExtractor(window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: 0.1190\n",
      "computers: 0.0784\n",
      "natural: 0.0774\n",
      "science: 0.0560\n",
      "computer: 0.0558\n",
      "artificial: 0.0557\n",
      "linguistics: 0.0555\n",
      "intelligence: 0.0555\n",
      "interactions: 0.0551\n",
      "rules: 0.0548\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence \n",
    "concerned with the interactions between computers and human language. It is used to apply algorithms to identify \n",
    "and extract the natural language rules such that unstructured language data is converted into a form that computers \n",
    "can understand.\n",
    "\"\"\"\n",
    "\n",
    "keywords = extractor.extract_keywords(text, top_n=10)\n",
    "for word, score in keywords:\n",
    "    print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Co-occurrence Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and export the graph\n",
    "graph = extractor.build_cooccurrence_graph(text)\n",
    "extractor.export_pajek(graph, '../data/example_graph.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_rank.utils import analyze_text_file\n",
    "\n",
    "# Analyze a single file (all keywords)\n",
    "keywords = analyze_text_file('../data\\text_examples\\._C-41.txt.tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thou: 0.0144\n",
      "thy: 0.0137\n",
      "good: 0.0098\n",
      "thee: 0.0083\n",
      "man: 0.0075\n"
     ]
    }
   ],
   "source": [
    "for i, (word, score) in enumerate(keywords):\n",
    "    print(f\"{word}: {score:.4f}\")\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Pajek Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get all text files from data/text_examples directory\n",
    "text_files_dir = os.path.join('..', 'data', 'text_examples')\n",
    "file_paths = [\n",
    "    os.path.join(text_files_dir, f) \n",
    "    for f in os.listdir(text_files_dir) \n",
    "    if f.endswith('.txt')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_rank.utils import export_multiple_graphs_to_pajek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = export_multiple_graphs_to_pajek(\n",
    "    file_paths=file_paths,\n",
    "    output_dir=text_files_dir,\n",
    "    window_size=5,\n",
    "    single_file=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_rank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
